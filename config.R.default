config <- function() { 
  list (
    fs = "hdfs://on-hadoop-master1.daum.net:8020",
    jt = "on-hadoop-master1.daum.net:8021",
    jar = list (
      mr = "analytics.jar",
      rmr = "rmr.jar"
    ),
    
    db = list (
      driver = "PostgreSQL",
      user = "",
      password = "",
      dbname = "valuepotion",
      host = "pg-dashboard.cv0lwhza2lbz.ap-southeast-1.rds.amazonaws.com",
      port = 5432L
	), 

    job = list (
      base_dir = "/user/hdfs/analytics",
      tasks = list (
        rfm = list (
          main = "com.valuepotion.analytics.lifecycle.RFM",
          properties = list (
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),

        grouping = list (
          main = "com.valuepotion.analytics.lifecycle.Grouping",
          properties = list (
            mapred.reduce.tasks = 20,
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),

        params = list (
          main = "alephomega.johan.mr.MapReduceDriver",
          properties = list (
            mapred.reduce.tasks = 60,
			mapred.task.timeout=0,
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),

        reset = list (
          main = "com.valuepotion.analytics.DoNothing",
          properties = list (
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),
 
        palive = list (
          main = "alephomega.johan.mr.MapReduceDriver",
          properties = list (
            mapred.reduce.tasks = 0,
			mapred.task.timeout=0,
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),

        phases = list (
          main = "com.valuepotion.analytics.lifecycle.Phases",
          properties = list (
            mapred.reduce.tasks = 5,
            mapred.max.split.size = 67108864,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512
          ),

          overwrite = TRUE
        ),

        hiveload = list (
          main = "com.valuepotion.analytics.lifecycle.LoadToHive",
          properties = list (
            mapred.reduce.tasks = 50,
            mapred.job.shuffle.input.buffer.percent = 0.3,
            mapred.max.split.size = 67108864L,
            mapred.child.java.opts = "-Xmx1024m",
            io.file.buffer.size = 65536,
            io.sort.mb = 512,
            mapred.compress.map.output = TRUE,
            mapred.map.output.compression.codec = "org.apache.hadoop.io.compress.SnappyCodec",
            mapred.reduce.tasks.speculative.execution = FALSE,
            hive.metastore.uris = "thrift://on-hadoop-master2.daum.net:9083"
          ), 
          
          output = list (
            database = "valuepotion_real",
            table = "lifecycle_phases"
          )
        ),
 
        drop = list(
          properties = list(
            hive.host = "on-hadoop-master2.daum.net",
            hive.port = 10000L,
            hive.db = "valuepotion_real",
            hive.table = "lifecycle_phases"
          )
        )
      )
    )
  )
}
